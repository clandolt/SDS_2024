{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataScience with Spatial Computing\n",
    "\n",
    "**Explore your data in Augmented and Virtual Reality using PlotAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING!**\n",
    "> \n",
    "> PlotAR is an alpha versioned package and is published as-is and without any guarantees. This means: APIs can change, sometimes it is instable, and security is not a priority at this moment. This also means, that your data could be accessed by others who can access your server.\n",
    "> \n",
    "> **We do not recommend to use this for sensitive data at the moment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the PlotAR Hands-On notebook.\n",
    "\n",
    "In this notebook we have first some curated examples for the workshop. In the second part there are many more examples we have done in the past. You can try them out as you go along. Open the Table of Contents pane to the left (where by default the file browser is) for an overview.\n",
    "\n",
    "If you like PlotAR consider leaving a star at <https://www.github.com/thomann/plotAR>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparisons with 2d plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, JSON, display\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canton of Zurich Relief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with some geo-spatial data that we prepared. The somewhat involved details of the data preparation using geopandas etc. can be seen in [this Notebook Gist](https://gist.github.com/thomann/7c74e72f003eedfb0823b054f1f021f6#file-flights-ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('data/canton_zrh.npz', ) as canton_zrh:\n",
    "    dhm=canton_zrh['dhm']\n",
    "    landsat=canton_zrh['landsat']\n",
    "    dhm_lon_lv95 = canton_zrh['dhm_lon_lv95']\n",
    "    dhm_lat_lv95 = canton_zrh['dhm_lat_lv95']\n",
    "    center = canton_zrh['center']\n",
    "    ground = canton_zrh['ground']\n",
    "f\"{dhm.shape=} {landsat.shape=} {dhm_lon_lv95.shape=} {dhm_lat_lv95.shape=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These datasets are:\n",
    "* `dhm`: the Digital Height Model\n",
    "* `landsat`: satellite image\n",
    "* `dhm_lon_lv95` and `dhm_lat_lv95`: the respective longitude and latitude values of the grid - in [LV95 System](https://www.swisstopo.admin.ch/de/schweizer-koordinatensystem), that is in meters.\n",
    "* `center`: the coordinate of the center of this grid (in lv95)\n",
    "* `ground`: the lowest altitude of this grid (in meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{center=} {ground=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's look at the height model data, this is in meter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(dhm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the satellite image (in RGB) - to reduce the image size we only show every 10th pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(landsat[::10,::10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values now are in meter, we do not want PlotAR to squeeze everything into a box, so we will do the scaling ourselves. Some testing showed that a scale of 1:40'000 looks good. Also we want to overstate the height by a factor of 5 to see it better.\n",
    "\n",
    "Also we decrease the satellite image for network and performance reason - keep the factor a smaller integer for more details.\n",
    "\n",
    "You can play around with different values and look what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE = 1 / 40000\n",
    "HEIGHT_FACTOR = 5\n",
    "\n",
    "IMAGE_DECREASE_BY_FACTOR = 5 ## has to be an integer >= 1\n",
    "surfacecolor = landsat[::IMAGE_DECREASE_BY_FACTOR,::IMAGE_DECREASE_BY_FACTOR,:]\n",
    "\n",
    "# make sure the bottom of the heigts is at -1\n",
    "heights = dhm - ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create our first immersive plot with PlotAR's surfacevr function.\n",
    "For that we need:\n",
    "* first argument is the grid/matrix of heights. We have to scale this height to be consistent with the other parameters.\n",
    "* `x` and `y` give the coordinates along the edges of the grid. We want them to be centered around `(0,0)` and scaled as well.\n",
    "* `surfacecolor` can be any image, it will be projected on the surface, here we use a downsampled version of the landsat image.\n",
    "* Lastly we specify a `name` that will be part of the plot.\n",
    "\n",
    "Now plot the surface and save it in the `fig`-variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotar.surfacevr(\n",
    "    heights * SCALE * HEIGHT_FACTOR,\n",
    "    x=(dhm_lon_lv95 - center[0]) * SCALE,\n",
    "    y=(dhm_lat_lv95 - center[1]) * SCALE,\n",
    "    surfacecolor=surfacecolor,\n",
    "    auto_scale=False,\n",
    "    name=\"Zurich Landsat/Height\",\n",
    ")\n",
    "# print the fig to see it in here\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you can use your mouse to zoom and rotate this plot as usual.\n",
    "\n",
    "Then however go and scan the QR code with your Tablet of Smartphone to get to the same page on that device.\n",
    "\n",
    "**Note:** Only Safari and Chrome work - Firefox mobile did not work in our tests (neither on iOS nor on Android). Furthermore in iOS rather use the Camera App to scan the QR code and not the QR-Scanning App (you then would proabably need to open the link in Safari)\n",
    "\n",
    "After that click in the lower right corner of the (possibly very wide) model viewer to start Augmented Reality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Flights in and out of Zurich Airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's grab some flights trajectories from [OpenSky Network](https://opensky-network.org). This is a network of ADS-B receivers around the glote. We have here some flights on Monday 2022-06-20 between 8am and 9am (UTC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv(\"./data/flights_zrh.csv\")\n",
    "flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for each flight (`callsign`) we have a timeseries (`time`) of different physical parameters: location, altitude, and velocity. We already have the lat and lon in a LV95-Version and the altitudes in meter, so we are set to plot the trajectories.\n",
    "\n",
    "For this plot we use the following arguments:\n",
    "* first argument is just the DataFrame, this works like e.g. in Plotly as we will see.\n",
    "* `x`,`y`,`z`: are the coordinates in 3D space. We recenter and scale manually like in the surface plot.\n",
    "* with the `col` parameter we set the color like in other plot libraries. This now specifices just the `callsign` column of the plots dataframe, i.e. `flights`. in a line plot this also gives the grouping so that PlotAR knows to what records belong to the same line.\n",
    "* `type` gives the type of the plot, here we only want the line without scatter spheres.\n",
    "* `width` is the width of the line.\n",
    "* Finally `surface` here is the figure from the relief above - this just adds it to the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = flights\n",
    "plot = plotar.linear(\n",
    "    _,\n",
    "    x=(_.lon_lv95 - center[0]) * SCALE,\n",
    "    y=(_.lat_lv95 - center[1]) * SCALE,\n",
    "    z=(_.baroaltitude_m - ground) * SCALE * HEIGHT_FACTOR,\n",
    "    auto_scale=False,\n",
    "    col='callsign',\n",
    "    col_labels=False, #there are too many to show\n",
    "    type='l', width=0.5,\n",
    "    name=\"Flights around Zurich over Relief\",\n",
    "    surface=fig,\n",
    ")\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorenz Attractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lorenz system is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz [[source: Wikipedia](https://en.wikipedia.org/wiki/Lorenz_system)]:\n",
    "<math> \\begin{align}\n",
    "\\frac{\\mathrm{d}x}{\\mathrm{d}t} &= \\sigma (y - x), \\\\[6pt]\n",
    "\\frac{\\mathrm{d}y}{\\mathrm{d}t} &= x (\\rho - z) - y, \\\\[6pt]\n",
    "\\frac{\\mathrm{d}z}{\\mathrm{d}t} &= x y - \\beta z.\n",
    "\\end{align} </math>\n",
    "> The equations relate the properties of a two-dimensional fluid layer uniformly warmed from below and cooled from above. In particular, the equations describe the rate of change of three quantities with respect to time: $x$ is proportional to the rate of convection, $y$ to the horizontal temperature variation, and $z$ to the vertical temperature variation. The constants σ, ρ, and β are system parameters proportional to the Prandtl number, Rayleigh number, and certain physical dimensions of the layer itself.\n",
    "\n",
    "The Lorenz Attractor is a set of solutions to this system and a prominent example of chaotic behaviour.\n",
    "\n",
    "We will not get into interpreting this too much, but just to show you something, that you might have seen in 2D before, in its natural habitat 3D.\n",
    "\n",
    "Let's quickly calculate solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 28.0\n",
    "sigma = 10.0\n",
    "beta = 8.0 / 3.0\n",
    "\n",
    "def f(state, t):\n",
    "    x, y, z = state  # Unpack the state vector\n",
    "    return sigma * (y - x), x * (rho - z) - y, x * y - beta * z  # Derivatives\n",
    "\n",
    "state0 = np.array([1.0, 1.0, 1.0])\n",
    "t = np.arange(0.0, 40.0, 0.01)\n",
    "\n",
    "states = odeint(f, state0, t)\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.linear(states, auto_scale=True, type='l', name=\"lorenz\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Embeddings of the SDS2024 events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having more dimensions is actually very useful when you have to do dimension reduction: instead of reducing 1536 dimensions to a plane, better reduce it to space!\n",
    "\n",
    "As an example we scraped all the events from <https://www.sds2024.ch> and will now use OpenAI embeddings for semantic similarity. After that we will perform dimension reduction with UMAP.\n",
    "\n",
    "In a later example below there are also variants with calculating the embeddings with sentence-transformers and also with PCA and T-SNE as dimension reduction algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.AzureOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds24 = pd.read_csv(\"./data/sds24.csv\")\n",
    "sds24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the Embeddings from Azure OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(input=sds24.description.str.replace(\"\\n\",\"\"), model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{response.usage=} {len(response.data)=})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the embeddings as a numpy matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds24_embeds = np.array([_.embedding for _ in response.data ])\n",
    "sds24_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_text(x, max_characters):\n",
    "    return pd.Series(x).map(lambda _: _ if len(_) <= max_characters-3 else _[:max_characters-3]+'...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First for comparison we plot this using Plotly in 2 dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = pd.DataFrame(umap.UMAP(n_components=2, random_state=42, n_jobs=1).fit_transform(sds24_embeds), columns=['x','y'])\n",
    "_ = sds24.copy()\n",
    "_[['x','y']] = pd.DataFrame(umap.UMAP(n_components=2, random_state=42, n_jobs=1).fit_transform(sds24_embeds))\n",
    "display(_.head())\n",
    "\n",
    "px.scatter(\n",
    "    _, 'x','y',\n",
    "    text=crop_text(sds24.name, 15),\n",
    "    color='format',\n",
    "    height=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now in 3D. We use PlotARs scatter plot with text-labels:\n",
    "* first argument is the DataFrame we use.\n",
    "* `xyz` specifies the coordinates in space for each entry\n",
    "* `label` is the title of the event\n",
    "* `col` specifies the color of the sphere and adds the legend to understand it\n",
    "* we disable `axis_names` because they have not much meaning here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sds24.copy()\n",
    "_[['x','y','z']] = pd.DataFrame(umap.UMAP(n_components=3, random_state=42, n_jobs=1).fit_transform(sds24_embeds), columns=['x','y','z'])\n",
    "display(_.head())\n",
    "\n",
    "plotar.plotar(\n",
    "    _,\n",
    "    xyz=['x','y','z'],\n",
    "    label=crop_text(sds24.name, 30),\n",
    "    col='format',\n",
    "    axis_names=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More examples to try out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAPminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the example on country development: **Gapminder**\n",
    "\n",
    "This was made famouse by Hans Rosling's [Lecture](https://www.youtube.com/watch?v=jbkSRLYSojo) showing how world wars etc. and general development shaped countries by looking at ther income per capita, life expectancy and population as size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/UofTCoders/2018-09-10-utoronto/raw/gh-pages/data/world-data-gapminder.csv'\n",
    "gap = pd.read_csv(url)\n",
    "gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep it simple let's look only at some European countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    " 'Austria',\n",
    " 'Switzerland',\n",
    " 'Spain',\n",
    " 'Poland',\n",
    " 'Italy',\n",
    " 'Greece',\n",
    " 'Germany',\n",
    " 'France',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_subset = gap.query(\"country.isin(@countries)\")\n",
    "gap_subset = (\n",
    "    gap_subset.groupby(['country',gap_subset.year.round(-1)])[['population', 'income','life_expectancy']]\n",
    "    .mean().round().astype(int).reset_index()\n",
    ")\n",
    "gap_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first plot the time series of *life expectancy* by *country* in a classical line plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(gap_subset, x='year', y='life_expectancy',\n",
    "              color='country',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we would like to add some more information? For instance the *income* and *population*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.linear(gap_subset, xyz=['year', 'income','life_expectancy'],\n",
    "              col='country', size='population')\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAPminder animated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do animation in PlotAR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plotar.animate(gap_subset, xyz=['year', 'income','life_expectancy'],\n",
    "    group='country', col='country', size='population', animation_frame='year',\n",
    "    name=\"gapminder-animated\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spheres are nice, however we don't know which dot is which country - so take the country name directly to the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plotar.animate(gap.query(\"region=='Europe'\"), xyz=['children_per_woman','income','life_expectancy'],\n",
    "    group='country', col='sub_region', size='population', animation_frame='year',\n",
    "    label = 'country', name=\"gapminder-animated-label\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D ONE Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scrape the http://d-one.ai/team webpage and extract some features on the team member's description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://d-one.ai/team'\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "x = soup.find_all(\"div\", class_=\"details\")\n",
    "team = pd.DataFrame( dict(name=_.find_all('h3')[0].text, text=_.find_all('p')[0].text) for _ in x )\n",
    "team = team.drop_duplicates('name')\n",
    "team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract two approximate counts: number of words and number of sentence (the latter actuall fails e.g. if many Abbreviations are used :-| )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team['n_sent'] = team.text.str.replace(r'[^.]','', regex=True).str.len()\n",
    "team['n_word'] = team.text.str.replace(r'[^ ]','', regex=True).str.len()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the last mentioned year - usually that is, when people started. If we do not find one, take 2000 as a default value - that is before the company was founded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = team.text.apply(lambda x: ([2000] + [_ for _ in x.split() if _.startswith(\"20\")])[-1])\n",
    "team['year_start'] = years.astype(str).str.rstrip('.').astype(int)\n",
    "team['year_start'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team['dr'] = team.name.str.startswith(\"Dr.\")\n",
    "team['dr'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.plotar(team, xyz=['n_word', 'n_sent', 'year_start'], col='dr',\n",
    "    label='name')\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write(\"examples/d-one-team.json\", format=\"json gltf glb usda usdz\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/metaverse_embeds.json\") as f:\n",
    "    metaverse = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = pd.DataFrame(metaverse)\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(embed.vector.to_list())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=3, random_state=42).fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = PCA(n_components=3, random_state=42).fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded =umap.UMAP(n_components=3, random_state=42).fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.plotar(X_embedded, label=embed.title, size=embed.nword)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write('examples/wikipedia-metaverse.json', format=[\"json\",\"usdz\",\"glb\",\"html\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = pd.read_csv('data/glove-wiki-gigaword-50.gz',sep=' ', quotechar=\";\",\n",
    "              skiprows=99,header=None,nrows=400, compression='gzip')\n",
    "glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded =umap.UMAP(n_components=3, random_state=42).fit_transform(glove.iloc[:200,1:])\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_embedded.shape[0]\n",
    "plot = plotar.plotar(X_embedded, label=glove[0][:n], size=1/(glove[:n].index+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write('examples/glove-wikipedia.json', format=[\"json\",\"usdz\",\"glb\",\"html\",\"gltf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write('examples/glove-wikipedia.json', format=[\"json\",\"usdz\",\"glb\",\"html\",\"gltf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove[0][90:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH - surface of Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [Swisstopo Digital Height Model](https://www.swisstopo.admin.ch/de/geodata/height/dhm25200.html) 200m grid to draw a surface of Swizterland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.geo.admin.ch/ch.swisstopo.digitales-hoehenmodell_25/data.zip'\n",
    "file_name = 'DHM200.asc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Zip file, unzip the part we need to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_download(url, file_name, cache=\"tmp\"):\n",
    "    file = Path(cache) / file_name\n",
    "    if not file.exists():\n",
    "        from io import BytesIO\n",
    "        from zipfile import ZipFile\n",
    "        import shutil\n",
    "        print(f\"Downloading {url} to {file} ...\")\n",
    "        zipfile = ZipFile(BytesIO(requests.get(url).content))\n",
    "        with open(file, 'wb') as f:\n",
    "            shutil.copyfileobj(zipfile.open(file_name), f)\n",
    "        print(f\"Downloaded {file} from {url}\")\n",
    "    else:\n",
    "        print(f\"getting {file} from cache\")\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = get_or_download(url, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GeoSpatial Information is in the first 6 rows of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_head = {k: float(v) for k,v in np.genfromtxt(file, dtype=str, max_rows=6)}\n",
    "print(y_head)\n",
    "y = np.genfromtxt(file, skip_header=6, skip_footer=1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = [int(y_head[_]) for _ in ['NCOLS','NROWS']]\n",
    "n,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = y.flatten()[:n*(m-1)].reshape((m-1,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is actually rather big - if you want you can make it smaller by setting factor to e.g. 5, 10, 20. We set it to 2 for mybinder.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[::factor,::factor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvec = np.arange(img.shape[1]) * y_head['CELLSIZE'] * factor\n",
    "yvec = np.arange(img.shape[0]) * y_head['CELLSIZE'] * factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute negative, i.e. NA values to some level below switerlands elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[img>0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[img<0] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly draw it here so we understand whats happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, interpolation='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually - since the Swiss geographical coordinate system (LV95) is in meters (our xvec and yvec), and the height is as well - this is in all our export formats a correct scale representation of the surface of switerzland!\n",
    "\n",
    "In the plots obviously it will be shown on a much smaller scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plotar.surfacevr(img, x=xvec, y=yvec, auto_scale=False, name=\"CH\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH-color - surface of Switzerland with color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add the official satellite image on top of that surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_file = get_or_download(\"https://data.geo.admin.ch/ch.swisstopo.images-landsat25/data.zip\", \"LandsatMos25.tif\")\n",
    "landsat_metadata_file = get_or_download(\"https://data.geo.admin.ch/ch.swisstopo.images-landsat25/data.zip\", \"Landsatmos25.TFW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_head = np.genfromtxt(landsat_metadata_file).astype(np.int64)\n",
    "sat_head.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description [[Source](http://www.omg.unb.ca/~jonnyb/processing/geotiff_tifw_format.html)]:\n",
    "* First row is x-pixel resolution\n",
    "* Second and third rows are so-called \"rotational components\" but are set to zero in the case of an unrotated mapsheet.\n",
    "* The fourth row is the y-pixel resolution. The negative sign indicates that the image y-axis is positive down which is the opposite from real world coordinates.\n",
    "* The 5th and 6th rows are the Easting and Northing of the upper left pixel (0,0 in image coordinates). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare `y_head` and `sat_head` you see that unfortunately we need to crop the satellite to match the frame of the surface data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = (\n",
    "    -sat_head[4] + (y_head['XLLCORNER']),\n",
    "    sat_head[5] - (y_head['YLLCORNER'] + y_head['CELLSIZE'] * y_head['NROWS']),\n",
    ")\n",
    "crop = crop + (\n",
    "    crop[0] + y_head['CELLSIZE'] * y_head['NCOLS'],\n",
    "    crop[1] + y_head['CELLSIZE'] * y_head['NROWS'],\n",
    ")\n",
    "np.array(crop)/25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat = Image.open(landsat_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No crop it and rescale it to the size of the surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_small = landsat.crop(np.array(crop)/25.0).resize(reversed(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_small.size, np.array(landsat_small).shape, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No plot it and resize it - also exaggerate the height by a factor ~3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plotar.surfacevr(img/100000, x=xvec/300000, y=yvec/300000, surfacecolor=np.array(landsat_small),\n",
    "                             auto_scale=False, name=\"CH-color\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write(\"examples/CH-color.json\", format=\"json gltf glb usda usdz\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the position of the Planets in the solar system at some time using the skyfield package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import Loader\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = Loader(\"./tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = load.timescale()\n",
    "t = ts.utc(2022, 5, 22, 15, 19)\n",
    "tarr = ts.utc(2022, 5, range(-365,365, 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** on mybinder.org unfortunately ftp-downloads are blocked so this will run into a timeout. We are preparing a workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets = load('de421.bsp')  # ephemeris DE421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_names = [ _[-1] for i,_ in planets.names().items() if 0 < i < 100 ]\n",
    "print(len(planet_names))\n",
    "planet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = \"\"\"i\tName\tEquatorial diameter [i]\tMass [i]\tSemi-major axis (AU)\tOrbital period (years)\tInclination to Sun's equator (°)\tOrbital eccentricity\tRotation period (days)\tConfirmed moons\tAxial tilt (°)\tRings\tAtmosphere\n",
    "1.\tMercury\t0.383\t0.06\t0.39\t0.24\t3.38\t0.206\t58.65\t0\t0.10\tno\tminimal\n",
    "2.\tVenus\t0.949\t0.81\t0.72\t0.62\t3.86\t0.007\t−243.02\t0\t177.30\tno\tCO2, N2\n",
    "3.\tEarth\t1.000\t1.00\t1.00\t1.00\t7.25\t0.017\t1.00\t1\t23.44\tno\tN2, O2, Ar\n",
    "4.\tMars\t0.532\t0.11\t1.52\t1.88\t5.65\t0.093\t1.03\t2\t25.19\tno\tCO2, N2, Ar\n",
    "5.\tJupiter\t11.209\t317.83\t5.20\t11.86\t6.09\t0.048\t0.41\t79\t3.12\tyes\tH2, He\n",
    "6.\tSaturn\t9.449\t95.16\t9.54\t29.45\t5.51\t0.054\t0.44\t82\t26.73\tyes\tH2, He\n",
    "7.\tUranus\t4.007\t14.54\t19.19\t84.02\t6.48\t0.047\t−0.72\t27\t97.86\tyes\tH2, He, CH4\n",
    "8.\tNeptune\t3.883\t17.15\t30.07\t164.79\t6.43\t0.009\t0.67\t14\t29.60\tyes\tH2, He, CH4j\"\"\"\n",
    "planet_info = pd.read_csv(io.StringIO(_), delimiter='\\t').drop(columns=['i']).set_index(\"Name\")\n",
    "planet_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_info['Equatorial diameter [i]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_traj_xyz = pd.concat([\n",
    "    pd.DataFrame(planets[_].at(tarr).ecliptic_xyz().au.T, columns=list('xyz'))\n",
    "    .assign(planet=_).assign(t=tarr.utc_strftime())\n",
    "    for _ in planet_names\n",
    "])\n",
    "planets_traj_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.animate(planets_traj_xyz, xyz=['x','y','z'],\n",
    "              group='planet', col='planet', size=planet_info['Equatorial diameter [i]'].to_list()+[1,1],\n",
    "              animation_frame='t', name='planets')\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write(\"examples/planets.json\", format=\"json gltf glb usda usdz\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import N, W, wgs84, load\n",
    "from skyfield.functions import length_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flightradar24.com/flights/most-tracked'\n",
    "# flightradar24 refuses 'User-Agent': 'python-requests/2.25.1' with error 451 Unavailable For Legal Reasons\n",
    "res = requests.get(url, headers={'User-Agent': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_tracked = pd.DataFrame(res.json()['data'])\n",
    "most_tracked['name'] = most_tracked.fillna('_').apply(\n",
    "    lambda _: f\"{_.callsign} {_.from_city}->{_.to_city}\", axis=1)\n",
    "most_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flight(flight_id, name):\n",
    "    url = f'https://data-live.flightradar24.com/clickhandler/?version=1.5&flight={flight_id}'\n",
    "    res = requests.get(url)\n",
    "    trail = pd.DataFrame(res.json()['trail'])\n",
    "    trail['flight_id'] = flight_id\n",
    "#     trail['name'] = name\n",
    "    return trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.concat(( get_flight(_.flight_id, _.name) for _ in most_tracked.itertuples()), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail = most_tracked.merge(flights, on=\"flight_id\")\n",
    "trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = trail.apply(lambda _: wgs84.latlon(_.lat, _.lng, _.alt*10).at(t).position.m, axis=1)\n",
    "trail[['x','y','z']] = np.stack(_) / 1000\n",
    "trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.linear(trail, xyz=['x','y','z'], col='name', size=trail.spd/10, auto_scale=True, type='l', name='flights')\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLA 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Sola 2022](https://trackmaxx.ch/maps/?m=ec368d93-aff4-4a7e-b0a5-24b7f9683a32&style=swisstopo&legend=full&tracks=1,2,3,4,5,6,8,7,9,10,11,12,13,14,20&labels=iconsubergabebuchlern,iconsuebergaben,icstrecke10,icstrecke11,icstrecke14,icstrecke2,icstrecke3,icstrecke4,icstrecke5,icstrecke6,icstrecke7,icstrecke8,icugbucheggplatz,icstrecke9,icugegg,icugfelsenegg,icugfluntern,icugforch,icughoenggerberg,icugirchel,icuguetliberg,icugwitikon,icugzumikon&h=8d68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://tmxx-static.s3.amazonaws.com/ous/asvzsolazh/mapstudio/gpx/strecke01.gpx\"\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sola_track(strecke):\n",
    "    url = f\"https://tmxx-static.s3.amazonaws.com/ous/asvzsolazh/mapstudio/gpx/strecke{strecke:02}.gpx\"\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    x = soup.find_all(\"trkpt\")\n",
    "    track = pd.DataFrame( _.attrs for _ in x )\n",
    "    track['ele'] = pd.Series( _.ele.text for _ in x)\n",
    "    track = track.astype(float)\n",
    "    track['strecke'] = strecke\n",
    "    return track\n",
    "sola_track(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sola = pd.concat( (sola_track(_) for _ in range(1,15)), axis=0)\n",
    "sola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sola.plot.line('lon','lat',);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.linear(sola, xyz=['lon','lat','ele'], col=sola.strecke.astype(str), auto_scale=True, type='l', name=\"sola\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eyetracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<https://www.eyetracking-eeg.org/testdata.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyetracking_file = get_or_download(\"https://www.eyetracking-eeg.org/testdata/freeviewing.zip\", \"eyetracker_freeviewing.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.eyetracking-eeg.org/testdata/reading.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyetracking = pd.read_table('tmp/eyetracker_freeviewing.txt',\n",
    "    skiprows=20, header=None,\n",
    "    names=['Time', 'Type', 'Trial', 'L Dia [mm]', 'L Area [mm]', 'R Dia [mm]', 'R Area [mm]', 'L POR X [px]', 'L POR Y [px]', 'R POR X [px]', 'R POR Y [px]', 'Trigger']\n",
    ")\n",
    "eyetracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triggertypes = {\n",
    "    103: 'Start-event for synchronization',\n",
    "    12: 'Onset of a picture on the screen',\n",
    "    1: 'Onset of search target (grey disc) within picture',\n",
    "    99: 'Response: participant found the target and pressed a button.',\n",
    "    203: 'End-event for synchronization',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyetracking['Trigger'] = eyetracking.Trigger.map(triggertypes).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyetracking.head(10000).Trigger.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyetracking['group'] = (eyetracking.Trigger == eyetracking.Trigger.shift(1)).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyetracking.head(10000).query(\"Trigger != ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.linear(eyetracking.head(10000), xyz=['L POR X [px]', 'Time', 'L POR Y [px]'],\n",
    "    col='Trigger', #group='group',\n",
    "    type='l', width=0.1)\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://www.eyetracking-eeg.org/images/testdata/testdata_search.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write('examples/eyetracking.json', format=['json','html','glb','usdz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks a lot for trying PlotAR out - we hope we could open your mind with these experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
